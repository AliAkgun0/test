import os
import requests
import feedparser
from bs4 import BeautifulSoup
from datetime import datetime, timedelta, timezone
import time

# --- AYARLAR ---
TELEGRAM_TOKEN = os.environ.get("TELEGRAM_TOKEN")
CHAT_ID = os.environ.get("CHAT_ID")

# DÄ°KKAT: TekrarÄ± Ã¶nlemek iÃ§in sÃ¼reyi kÄ±stÄ±m. 
# Bot 20 dk'da bir Ã§alÄ±ÅŸÄ±yor, biz son 30 dk'ya bakacaÄŸÄ±z.
TIME_WINDOW_MINUTES = 30 

# --- KAMUFLAJ ---
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8",
    "Accept-Language": "tr-TR,tr;q=0.9,en-US;q=0.8,en;q=0.7",
    "Referer": "https://www.google.com.tr/"
}

# --- SÄ°TE YAPILANDIRMASI (METÄ°N NEREDE SAKLI?) ---
SITES = [
    {
        "name": "Sabah Spor", 
        "rss": "https://www.sabah.com.tr/rss/spor.xml",
        "selector": "div.newsDetail" # Sabah'Ä±n metin kutusu
    },
    {
        "name": "HÃ¼rriyet Spor", 
        "rss": "https://www.hurriyet.com.tr/rss/spor",
        "selector": "div.news-content" # HÃ¼rriyet'in metin kutusu
    },
    {
        "name": "Milliyet Spor", 
        "rss": "https://www.milliyet.com.tr/rss/rssNew/skorerRss.xml",
        "selector": "div.article-content" # Milliyet'in metin kutusu
    },
    {
        "name": "FotomaÃ§", 
        "rss": "https://www.fotomac.com.tr/rss/rssNew/futbolRss.xml",
        "selector": "div.detail-text-content" # FotomaÃ§'Ä±n metin kutusu
    },
    {
        "name": "Fanatik", 
        "rss": "https://www.fanatik.com.tr/rss/futbol",
        "selector": "div.article-body" # Fanatik'in metin kutusu
    }
]

def check_time(entry):
    """Haber son 30 dakika iÃ§inde mi?"""
    try:
        if hasattr(entry, 'published_parsed') and entry.published_parsed:
            pub_time = datetime(*entry.published_parsed[:6], tzinfo=timezone.utc)
            now = datetime.now(timezone.utc)
            diff = now - pub_time
            # Sadece son 30 dakikadaki haberleri al (TekrarÄ± Ã¶nler)
            if diff <= timedelta(minutes=TIME_WINDOW_MINUTES):
                return True
    except:
        pass
    return False

def get_news_details(url, selector):
    """Siteye gir, Ã¶zel kutudan metni ve resmi Ã§ek"""
    try:
        r = requests.get(url, headers=HEADERS, timeout=15)
        soup = BeautifulSoup(r.content, "html.parser")
        
        # 1. RESÄ°M
        img = soup.find("meta", property="og:image") or soup.find("meta", name="twitter:image")
        img_url = img["content"] if img else None

        # 2. METÄ°N (Nokta AtÄ±ÅŸÄ±)
        text_content = ""
        
        # Sitenin Ã¶zel metin kutusunu bul
        content_div = soup.select_one(selector)
        
        if content_div:
            # Sadece paragraflarÄ± al
            paragraphs = content_div.find_all(['p', 'h2', 'h3'])
            for p in paragraphs:
                text = p.get_text().strip()
                if len(text) > 30 and "tÄ±klayÄ±n" not in text.lower() and "abone" not in text.lower():
                    text_content += text + "\n\n"
        
        # EÄŸer Ã¶zel kutu boÅŸsa veya bulunamadÄ±ysa JSON-LD dene (Yedek)
        if not text_content:
            scripts = soup.find_all('script', type='application/ld+json')
            for script in scripts:
                if 'articleBody' in script.text:
                    try:
                        data = json.loads(script.text)
                        if isinstance(data, list): data = data[0]
                        text_content = data.get('articleBody', '')
                        break
                    except: pass

        # Yine boÅŸsa RSS Ã¶zetini al
        if not text_content:
            return img_url, "Detaylar haber linkindedir."

        # Telegram sÄ±nÄ±rÄ± (1000 karakter)
        if len(text_content) > 950:
            text_content = text_content[:950] + "..."

        return img_url, text_content

    except Exception as e:
        print(f"      Hata: {e}")
        return None, None

def send_telegram(title, text, image_url, site_name):
    # Kaynak Linki Yok, Sadece Metin
    caption = f"ğŸ“£ <b>{site_name}</b>\n\nğŸ”¹ <b>{title}</b>\n\n{text}"
    
    try:
        if image_url:
            url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendPhoto"
            payload = {"chat_id": CHAT_ID, "photo": image_url, "caption": caption, "parse_mode": "HTML"}
        else:
            url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
            payload = {"chat_id": CHAT_ID, "text": caption, "parse_mode": "HTML"}
        
        r = requests.post(url, data=payload)
        if r.status_code == 200:
            print(f"      âœ… Kanala GÃ¶nderildi.")
            return True
        elif r.status_code == 400 and "IMAGE_PROCESS_FAILED" in r.text:
             # Resim hatasÄ± verirse resimsiz dene
             print("      âš ï¸ Resim hatasÄ±, metin olarak deneniyor...")
             requests.post(f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage", 
                          data={"chat_id": CHAT_ID, "text": caption, "parse_mode": "HTML"})
             return True
    except:
        pass
    return False

def main():
    print(f"ğŸš€ Bot BaÅŸlatÄ±ldÄ± (Son {TIME_WINDOW_MINUTES} dakika)")
    
    for site in SITES:
        print(f"ğŸ” {site['name']} kontrol ediliyor...")
        try:
            resp = requests.get(site['rss'], headers=HEADERS, timeout=20)
            if resp.status_code != 200:
                print(f"   âš ï¸ EriÅŸim Engellendi: {resp.status_code}")
                continue

            feed = feedparser.parse(resp.content)
            
            # Ä°lk 5 haberi kontrol et
            yeni_yok = True
            for entry in feed.entries[:5]:
                if check_time(entry):
                    print(f"   ğŸ†• Haber: {entry.title}")
                    
                    # Ã–zel seÃ§iciyi (selector) fonksiyona gÃ¶nder
                    img_url, full_text = get_news_details(entry.link, site['selector'])
                    
                    if send_telegram(entry.title, full_text, img_url, site['name']):
                        time.sleep(5)
                        yeni_yok = False
            
            if yeni_yok:
                print("   ğŸ’¤ Yeni haber yok.")
                
        except Exception as e:
            print(f"   âŒ Hata: {e}")

if __name__ == "__main__":
    main()
