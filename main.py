import os
import json
import time
import requests
import feedparser
from bs4 import BeautifulSoup

# --- AYARLAR ---
TELEGRAM_TOKEN = os.environ.get("TELEGRAM_TOKEN")
CHAT_ID = os.environ.get("CHAT_ID")

# --- GELÄ°ÅMÄ°Å KAMUFLAJ ---
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
    "Accept-Language": "tr-TR,tr;q=0.9,en-US;q=0.8,en;q=0.7",
    "Referer": "https://www.google.com/"
}

SITES = [
    {"name": "FotomaÃ§", "rss": "https://www.fotomac.com.tr/rss/rssNew/futbolRss.xml"},
    {"name": "Fanatik", "rss": "https://www.fanatik.com.tr/rss/futbol"},
    {"name": "TRT Spor", "rss": "https://www.trtspor.com.tr/rss"},
    {"name": "NTV Spor", "rss": "https://www.ntvspor.net/rss"},
    {"name": "Sabah Spor", "rss": "https://www.sabah.com.tr/rss/spor.xml"}
]

# --- HAFIZA SÄ°STEMÄ° (Basit Dosya) ---
# GitHub Actions her Ã§alÄ±ÅŸtÄ±ÄŸÄ±nda sÄ±fÄ±rlanmasÄ±n diye basit bir mantÄ±k kuruyoruz.
# Ancak Actions'da kalÄ±cÄ± hafÄ±za zordur, bu yÃ¼zden son gÃ¶nderilenleri
# o anki Ã§alÄ±ÅŸmada hafÄ±zada tutup tekrarÄ± Ã¶nleyeceÄŸiz.
SENT_LINKS = set()

def get_news_details(url):
    """
    SayfanÄ±n iÃ§ine girer ve Google iÃ§in hazÄ±rlanan 
    GÄ°ZLÄ° JSON verisini (ld+json) okur. En temiz yÃ¶ntemdir.
    """
    try:
        response = requests.get(url, headers=HEADERS, timeout=20)
        soup = BeautifulSoup(response.content, "html.parser")

        # 1. RESÄ°M BULMA (Meta Etiketlerinden)
        img = soup.find("meta", property="og:image") or soup.find("meta", name="twitter:image")
        img_url = img["content"] if img else None

        # 2. Ä°Ã‡ERÄ°K BULMA (JSON-LD YÃ¶ntemi - AttÄ±ÄŸÄ±n kodlarda bu var!)
        text_content = ""
        scripts = soup.find_all('script', type='application/ld+json')
        
        for script in scripts:
            try:
                data = json.loads(script.string)
                # EÄŸer veri bir listeyse dÃ¶ngÃ¼ye al
                if isinstance(data, list):
                    for item in data:
                        if 'articleBody' in item:
                            text_content = item['articleBody']
                            break
                # EÄŸer veri sÃ¶zlÃ¼kse direkt bak
                elif isinstance(data, dict):
                    if 'articleBody' in data:
                        text_content = data['articleBody']
                        break
            except:
                continue
        
        # EÄŸer JSON'dan metin Ã§Ä±kmazsa klasik yÃ¶nteme dÃ¶n (<p> etiketleri)
        if not text_content:
            paragraphs = soup.find_all("p")
            for p in paragraphs:
                text = p.get_text().strip()
                if len(text) > 40 and "tÄ±klayÄ±n" not in text.lower():
                    text_content += text + "\n\n"

        # Temizlik ve KÄ±saltma
        text_content = text_content.replace("&nbsp;", " ").strip()
        
        # HTML taglerini temizle (bazen json iÃ§inde html kalabiliyor)
        text_content = BeautifulSoup(text_content, "html.parser").get_text()

        # Ã‡ok uzunsa kes (Telegram limiti 1024 karakter resim altÄ±nda)
        if len(text_content) > 900:
            text_content = text_content[:900] + "..."

        return img_url, text_content

    except Exception as e:
        print(f"      âŒ Detay Ã‡ekme HatasÄ±: {e}")
        return None, None

def send_telegram(title, text, image_url, site_name):
    # Mesaj Åablonu
    caption = f"ğŸ“£ <b>{site_name}</b>\n\nğŸ”¹ <b>{title}</b>\n\n{text}"
    
    try:
        if image_url:
            url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendPhoto"
            payload = {
                "chat_id": CHAT_ID, 
                "photo": image_url, 
                "caption": caption, 
                "parse_mode": "HTML"
            }
        else:
            url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
            payload = {
                "chat_id": CHAT_ID, 
                "text": caption, 
                "parse_mode": "HTML"
            }
        
        r = requests.post(url, data=payload, timeout=20)
        if r.status_code == 200:
            return True
        else:
            print(f"      âš ï¸ Telegram HatasÄ±: {r.text}")
            return False
    except Exception as e:
        print(f"      âŒ BaÄŸlantÄ± HatasÄ±: {e}")
        return False

def main():
    print("ğŸš€ Bot BaÅŸlatÄ±lÄ±yor... (JSON-LD Modu)")
    
    for site in SITES:
        print(f"ğŸ” {site['name']} taranÄ±yor...")
        try:
            # RSS'i requests ile Ã§ekiyoruz
            resp = requests.get(site['rss'], headers=HEADERS, timeout=20)
            if resp.status_code != 200:
                print(f"   âš ï¸ Siteye eriÅŸilemedi: {resp.status_code}")
                continue

            feed = feedparser.parse(resp.content)
            
            if not feed.entries:
                print("   âš ï¸ RSS BoÅŸ dÃ¶ndÃ¼!")
                continue
            
            # Sitenin EN YENÄ° haberini al (Sadece 1. sÄ±radaki)
            # Neden? Ã‡Ã¼nkÃ¼ sÃ¼rekli Ã§alÄ±ÅŸacaÄŸÄ± iÃ§in en Ã¼sttekini almasÄ± yeterli.
            # Eski haberleri tekrar atmamak iÃ§in basit bir mantÄ±k.
            entry = feed.entries[0]
            
            # Haber zaten hafÄ±zada mÄ±? (GitHub Actions her Ã§alÄ±ÅŸtÄ±ÄŸÄ±nda bu sÄ±fÄ±rlanÄ±r,
            # ama aynÄ± Ã§alÄ±ÅŸma dÃ¶ngÃ¼sÃ¼ iÃ§inde tekrarÄ± Ã¶nler)
            if entry.link in SENT_LINKS:
                continue

            print(f"   ğŸ‘‰ Ä°nceleniyor: {entry.title}")
            
            # DetaylarÄ± Ã‡ek
            img_url, full_text = get_news_details(entry.link)
            
            if not full_text:
                full_text = entry.get('summary', 'Detaylara ulaÅŸÄ±lamadÄ±.')

            # Telegram'a GÃ¶nder
            if send_telegram(entry.title, full_text, img_url, site['name']):
                print("      âœ… Kanala GÃ¶nderildi.")
                SENT_LINKS.add(entry.link)
                time.sleep(5) # Spam Ã¶nleme
            else:
                print("      âš ï¸ GÃ¶nderilemedi.")

        except Exception as e:
            print(f"   âŒ {site['name']} Kritik Hata: {e}")

if __name__ == "__main__":
    main()
